# 可解释性分析：白盒 π-Flight vs. 黑盒方法

## 结论概览
- π-Flight：★★★★★（白盒、规则+阈值+增益，易审计/验证/复用）
- CMA-ES：★★☆☆☆（参数可见但缺少结构语义，定位问题成本高）
- 神经网络：★☆☆☆☆（黑盒，高性能可达但难以验证与迁移）

## π-Flight 的可解释性优势
- 结构可读：每条规则即一条可口述的控制逻辑（条件→动作/增益）。
- 调参有据：P/I/D 的区间与作用段落可视化，支持“按条件分段”的安全裁剪与限幅。
- 追责与验证友好：可对每条规则做单元测试、极端工况验证与形式化检查（如边界/饱和/冲突）。
- 知识迁移：从一台机体迁移到另一台时，可逐条规则复用/微调，而非端到端重训。

## 黑盒方法的典型风险
- 强耦合：行为难以归因到具体“知识点”（如某条件/阈值/通道）。
- 诊断困难：异常只体现在输出统计或轨迹误差，缺可定位的因子。
- 可验证性差：在安全/合规背景下，需要大量冗余的回归测试才能保证边界安全。

## 实践建议
- 以 π-Flight 为主线，黑盒作为补充（如高频微调器、优先级低的行为层）。
- 面向安全关键场景，对规则集做：覆盖度测试、反例驱动增强、自动化极端工况回归。