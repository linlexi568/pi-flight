#!/bin/bash
################################################################################
# Pi-Flight 完整训练启动脚本
# 基于Sanity Check验证结果,使用120 MCTS simulations进行完整训练
################################################################################

set -e  # 遇到错误立即退出

# 颜色输出
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# 项目根目录
PROJECT_ROOT="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
cd "$PROJECT_ROOT"

# Python虚拟环境
VENV_PYTHON="$PROJECT_ROOT/.venv/bin/python"

# 检查虚拟环境
if [ ! -f "$VENV_PYTHON" ]; then
    echo -e "${RED}❌ 虚拟环境不存在: $VENV_PYTHON${NC}"
    echo "请先运行: python -m venv .venv && .venv/bin/pip install -r requirements.txt"
    exit 1
fi

# 创建必要目录
mkdir -p logs results 01_pi_flight/results

# 生成时间戳
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
LOG_FILE="logs/full_training_${TIMESTAMP}.log"
RESULT_FILE="01_pi_flight/results/phase1_full_training_${TIMESTAMP}.json"


CFG_ITERS=1000                # 总迭代数
CFG_SIMS=120                  # 每轮MCTS模拟次数
CFG_ENVS=512                  # 并行环境数量 (受GPU显存限制)
CFG_DURATION=8                # Episode持续秒数
CFG_TRAJ="hover"             # 任务类型: hover / tracking 等
CFG_EVAL_REPLICAS=4           # 每程序评估副本数
CFG_UPDATE_FREQ=10            # 每N轮更新一次GNN
CFG_TRAIN_STEPS=8             # 每次更新的训练步数
CFG_BATCH_SIZE=128            # 训练batch大小
CFG_MIN_STEPS_FRAC=0.3        # 最短步数比例
CFG_LR=1e-3                   # 学习率
CFG_CHECKPOINT_FREQ=100       # 保存checkpoint频率
CFG_REWARD_REDUCTION="mean"   # 奖励聚合方式: mean/max/last
CFG_STRICT_NO_PRIOR=true      # 严格无先验 (直接输出力/力矩)
CFG_REAL_SIM_FRAC=1.0         # 真实仿真比例(0~1)

#############################################
# 参数解析 (支持命令行与环境变量覆盖默认值)
#############################################

# 默认参数
DEFAULT_ITERS=${ITERS:-$CFG_ITERS}
DEFAULT_SIMS=${SIMS:-$CFG_SIMS}
DEFAULT_ENVS=${ENVS:-$CFG_ENVS}
DEFAULT_DURATION=${DURATION:-$CFG_DURATION}
DEFAULT_TRAJ=${TRAJ:-$CFG_TRAJ}
DEFAULT_EVAL_REPLICAS=${EVAL_REPLICAS:-$CFG_EVAL_REPLICAS}
DEFAULT_UPDATE_FREQ=${UPDATE_FREQ:-$CFG_UPDATE_FREQ}
DEFAULT_TRAIN_STEPS=${TRAIN_STEPS:-$CFG_TRAIN_STEPS}
DEFAULT_BATCH_SIZE=${BATCH_SIZE:-$CFG_BATCH_SIZE}
DEFAULT_MIN_STEPS_FRAC=${MIN_STEPS_FRAC:-$CFG_MIN_STEPS_FRAC}
DEFAULT_LR=${LR:-$CFG_LR}
DEFAULT_CHECKPOINT_FREQ=${CHECKPOINT_FREQ:-$CFG_CHECKPOINT_FREQ}
DEFAULT_REWARD_REDUCTION=${REWARD_RED:-$CFG_REWARD_REDUCTION}
STRICT_NO_PRIOR=${STRICT_NO_PRIOR:-$CFG_STRICT_NO_PRIOR}
DEFAULT_REAL_SIM_FRAC=${REAL_SIM_FRAC:-$CFG_REAL_SIM_FRAC}
EXTRA_ARGS=()
DRY_RUN=0
show_help() {
    cat << EOF
用法: ./train_full.sh [参数]

可用参数(均可用同名环境变量覆盖):
    --iters N              总迭代数 (默认: $DEFAULT_ITERS)
    --sims N               每轮MCTS模拟次数 (默认: $DEFAULT_SIMS)
    --envs N               并行环境数量 (默认: $DEFAULT_ENVS)
    --duration SEC         Episode持续秒数 (默认: $DEFAULT_DURATION)
    --traj NAME            轨迹任务 (默认: $DEFAULT_TRAJ)
    --eval-replicas N      每程序评估副本数 (默认: $DEFAULT_EVAL_REPLICAS)
    --update-freq N        每N轮更新一次GNN (默认: $DEFAULT_UPDATE_FREQ)
    --train-steps N        每次更新的训练步数 (默认: $DEFAULT_TRAIN_STEPS)
    --batch-size N         训练批大小 (默认: $DEFAULT_BATCH_SIZE)
    --min-steps-frac F     最短步数比例 (默认: $DEFAULT_MIN_STEPS_FRAC)
    --lr LR                学习率 (默认: $DEFAULT_LR)
    --checkpoint-freq N    保存checkpoint频率 (默认: $DEFAULT_CHECKPOINT_FREQ)
    --reward-reduction STR 奖励聚合方式 (默认: $DEFAULT_REWARD_REDUCTION)
    --strict-no-prior bool 是否严格无先验 (默认: $STRICT_NO_PRIOR)
    --real-sim-frac F      真实仿真比例0~1 (默认: $DEFAULT_REAL_SIM_FRAC)
    --dry-run              仅显示最终命令不执行
    --extra 'ARGS'         追加传递给Python的额外参数串
    --help                 显示本帮助

示例:
    ./train_full.sh --iters 500 --sims 150 --envs 256 --duration 6 \
            --traj hover --lr 5e-4 --extra '--seed 42 --debug'
EOF
}

# 简单参数解析循环
while [[ $# -gt 0 ]]; do
    case "$1" in
        --iters) DEFAULT_ITERS=$2; shift 2;;
        --sims) DEFAULT_SIMS=$2; shift 2;;
        --envs) DEFAULT_ENVS=$2; shift 2;;
        --duration) DEFAULT_DURATION=$2; shift 2;;
        --traj) DEFAULT_TRAJ=$2; shift 2;;
        --eval-replicas) DEFAULT_EVAL_REPLICAS=$2; shift 2;;
        --update-freq) DEFAULT_UPDATE_FREQ=$2; shift 2;;
        --train-steps) DEFAULT_TRAIN_STEPS=$2; shift 2;;
        --batch-size) DEFAULT_BATCH_SIZE=$2; shift 2;;
        --min-steps-frac) DEFAULT_MIN_STEPS_FRAC=$2; shift 2;;
        --lr) DEFAULT_LR=$2; shift 2;;
        --checkpoint-freq) DEFAULT_CHECKPOINT_FREQ=$2; shift 2;;
        --reward-reduction) DEFAULT_REWARD_REDUCTION=$2; shift 2;;
        --strict-no-prior) STRICT_NO_PRIOR=$2; shift 2;;
        --real-sim-frac) DEFAULT_REAL_SIM_FRAC=$2; shift 2;;
        --dry-run) DRY_RUN=1; shift;;
        --extra) EXTRA_ARGS+=("$2"); shift 2;;
        --help) show_help; exit 0;;
        *) echo -e "${YELLOW}跳过未知参数: $1${NC}"; shift;;
    esac
done

echo -e "${BLUE}╔════════════════════════════════════════════════════════════════╗${NC}"
echo -e "${BLUE}║           Pi-Flight 完整训练 - Phase 1 Hover Control          ║${NC}"
echo -e "${BLUE}╚════════════════════════════════════════════════════════════════╝${NC}"
echo ""
echo -e "${GREEN}📋 训练配置:${NC}"
echo -e "  训练模式: AlphaZero (MCTS + GNN Policy/Value Network)"
echo -e "  任务类型: ${DEFAULT_TRAJ}"
echo -e "  控制模式: 严格无先验 (${STRICT_NO_PRIOR})"
echo -e "  总迭代数: ${DEFAULT_ITERS}"
echo -e "  MCTS模拟: ${DEFAULT_SIMS} 次/迭代"
echo -e "  并行环境: ${DEFAULT_ENVS} 个 (Isaac Gym GPU)"
echo -e "  Episode时长: ${DEFAULT_DURATION} 秒"
echo -e "  评估副本: ${DEFAULT_EVAL_REPLICAS} 次/程序"
echo -e "  更新频率: 每 ${DEFAULT_UPDATE_FREQ} 轮更新GNN"
echo -e "  每次更新训练步: ${DEFAULT_TRAIN_STEPS}"
echo -e "  Batch Size: ${DEFAULT_BATCH_SIZE}"
echo -e "  Min Steps Frac: ${DEFAULT_MIN_STEPS_FRAC}"
echo -e "  学习率: ${DEFAULT_LR}"
echo -e "  Checkpoint频率: ${DEFAULT_CHECKPOINT_FREQ}"
echo -e "  奖励聚合: ${DEFAULT_REWARD_REDUCTION}"
echo -e "  真实仿真比例: ${DEFAULT_REAL_SIM_FRAC}"
if [ ${#EXTRA_ARGS[@]} -gt 0 ]; then
    echo -e "  额外参数: ${EXTRA_ARGS[*]}"
fi
echo ""
echo -e "${YELLOW}💾 输出文件:${NC}"
echo -e "  日志文件: $LOG_FILE"
echo -e "  结果文件: $RESULT_FILE"
echo ""

# 确认启动
read -p "$(echo -e ${YELLOW}是否开始训练? [y/N]: ${NC})" -n 1 -r
echo
if [[ ! $REPLY =~ ^[Yy]$ ]]; then
    echo -e "${RED}❌ 训练已取消${NC}"
    exit 0
fi

echo ""
echo -e "${GREEN}🚀 启动训练...${NC}"
echo ""

# 启动训练并实时显示输出
export DEBUG_STEPWISE=1  # 启用调试输出

CMD=("$VENV_PYTHON" 01_pi_flight/train_online.py \
        --use-gnn \
        --traj "${DEFAULT_TRAJ}" \
        --duration "${DEFAULT_DURATION}" \
        --total-iters "${DEFAULT_ITERS}" \
        --mcts-simulations "${DEFAULT_SIMS}" \
    --real-sim-frac "${DEFAULT_REAL_SIM_FRAC}" \
        --update-freq "${DEFAULT_UPDATE_FREQ}" \
        --train-steps-per-update "${DEFAULT_TRAIN_STEPS}" \
        --batch-size "${DEFAULT_BATCH_SIZE}" \
        --isaac-num-envs "${DEFAULT_ENVS}" \
        --eval-replicas-per-program "${DEFAULT_EVAL_REPLICAS}" \
        --min-steps-frac "${DEFAULT_MIN_STEPS_FRAC}" \
        --reward-reduction "${DEFAULT_REWARD_REDUCTION}" \
        --learning-rate "${DEFAULT_LR}" \
        --checkpoint-freq "${DEFAULT_CHECKPOINT_FREQ}" \
        --save-path "$RESULT_FILE")

if [ "$STRICT_NO_PRIOR" != "true" ]; then
    CMD+=(--strict-no-prior false)
fi

if [ ${#EXTRA_ARGS[@]} -gt 0 ]; then
    CMD+=("${EXTRA_ARGS[@]}")
fi

echo -e "${BLUE}🔧 最终执行命令:${NC}"
printf '  %q' "${CMD[@]}"; echo ""

if [ $DRY_RUN -eq 1 ]; then
    echo -e "${YELLOW}🧪 Dry-run模式: 不执行训练${NC}"
    exit 0
fi

"$VENV_PYTHON" 01_pi_flight/train_online.py \
    --use-gnn \
    --traj "${DEFAULT_TRAJ}" \
    --duration "${DEFAULT_DURATION}" \
    --total-iters "${DEFAULT_ITERS}" \
    --mcts-simulations "${DEFAULT_SIMS}" \
    --real-sim-frac "${DEFAULT_REAL_SIM_FRAC}" \
    --update-freq "${DEFAULT_UPDATE_FREQ}" \
    --train-steps-per-update "${DEFAULT_TRAIN_STEPS}" \
    --batch-size "${DEFAULT_BATCH_SIZE}" \
    --isaac-num-envs "${DEFAULT_ENVS}" \
    --eval-replicas-per-program "${DEFAULT_EVAL_REPLICAS}" \
    --min-steps-frac "${DEFAULT_MIN_STEPS_FRAC}" \
    --reward-reduction "${DEFAULT_REWARD_REDUCTION}" \
    --learning-rate "${DEFAULT_LR}" \
    --checkpoint-freq "${DEFAULT_CHECKPOINT_FREQ}" \
    --save-path "$RESULT_FILE" \
    2>&1 | tee "$LOG_FILE"

EXIT_CODE=${PIPESTATUS[0]}

echo ""
if [ $EXIT_CODE -eq 0 ]; then
    echo -e "${GREEN}╔════════════════════════════════════════════════════════════════╗${NC}"
    echo -e "${GREEN}║                    ✅ 训练成功完成!                            ║${NC}"
    echo -e "${GREEN}╚════════════════════════════════════════════════════════════════╝${NC}"
    echo ""
    echo -e "${BLUE}📊 结果文件: $RESULT_FILE${NC}"
    echo -e "${BLUE}📄 日志文件: $LOG_FILE${NC}"
    echo ""
    echo -e "${YELLOW}下一步操作:${NC}"
    echo -e "  1. 分析训练结果: python analyze_sanity_check.py"
    echo -e "  2. 查看最佳程序: cat $RESULT_FILE | jq '.best_program'"
    echo -e "  3. 可视化轨迹: python 01_pi_flight/test_online_system.py --load $RESULT_FILE"
else
    echo -e "${RED}╔════════════════════════════════════════════════════════════════╗${NC}"
    echo -e "${RED}║                    ❌ 训练异常终止                             ║${NC}"
    echo -e "${RED}╚════════════════════════════════════════════════════════════════╝${NC}"
    echo ""
    echo -e "${YELLOW}退出代码: $EXIT_CODE${NC}"
    echo -e "${YELLOW}请检查日志: $LOG_FILE${NC}"
    exit $EXIT_CODE
fi
